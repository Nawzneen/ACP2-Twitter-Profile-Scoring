{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import call\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,\n",
    "                             mean_squared_log_error, median_absolute_error)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataset_reader import get_dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = get_dataset()\n",
    "df = df.drop('id', axis=1)\n",
    "print(f\"Dataset size: {df.shape[0]} rows\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for test and train sets\n",
    "dataset_df = df.dropna()\n",
    "\n",
    "train_df, test_df = train_test_split(dataset_df, train_size=0.8)\n",
    "y_variable = \"credibility_score\"\n",
    "train_x = train_df.drop(y_variable, axis=1)\n",
    "test_x = test_df.drop(y_variable, axis=1)\n",
    "train_y = train_df[y_variable].astype(int)\n",
    "test_y = test_df[y_variable].astype(int)\n",
    "\n",
    "print(f\"Training data rows: {train_df.shape[0]}\")\n",
    "print(f\"Test data rows: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "train_x_scaled = pd.DataFrame(train_x_scaled, columns=train_x.columns)\n",
    "model.fit(train_x_scaled, train_y)\n",
    "prediction = model.predict(test_x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate errors\n",
    "\n",
    "test_y_np = test_y.to_numpy()\n",
    "test_mse = mean_squared_error(test_y_np, prediction)\n",
    "test_msle = mean_squared_log_error(test_y_np, prediction)\n",
    "test_mdae = median_absolute_error(test_y_np, prediction)\n",
    "test_mae = mean_absolute_error(test_y_np, prediction)\n",
    "test_mape = mean_absolute_percentage_error(test_y_np, prediction)\n",
    "print(f\"Mean squared error: {test_mse}\")\n",
    "print(f\"Mean squared log error: {test_msle}\")\n",
    "print(f\"Median absolute error: {test_mdae}\")\n",
    "print(f\"Mean absolute error: {test_mae}\")\n",
    "print(f\"Mean absolute percentage error {test_mape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "\n",
    "feature_names = list(dataset_df.columns)\n",
    "feature_names.remove(y_variable)\n",
    "\n",
    "# estimator = model.estimators_[5]\n",
    "# def get_feature_importances(estimator):\n",
    "#     importances = []\n",
    "#     for i, feature_name in enumerate(feature_names):\n",
    "#         importances.append(\n",
    "#             {\"importance\": estimator.feature_importances_[i], \"feature_name\": feature_name})\n",
    "#     importances = sorted(importances, key=lambda x: x[\"importance\"], reverse=True)\n",
    "#     return importances\n",
    "\n",
    "# importances = get_feature_importances(estimator)\n",
    "# importance_msg = \"\\n\".join(f\"{i['feature_name']}: {i['importance']:.3f}\" for i in importances)\n",
    "# print(importance_msg)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_imp = permutation_importance(\n",
    "    model, test_x_scaled, test_y, n_repeats=10, n_jobs=2\n",
    ")\n",
    "forest_importances = pd.Series(perm_imp.importances_mean, index=feature_names)\n",
    "forest_importances = forest_importances.sort_values()\n",
    "print(\"IMP:\" + str(forest_importances))\n",
    "print(\"STD: \" + str(perm_imp.importances_std))\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=perm_imp.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "\n",
    "# Uncomment to update saved model\n",
    "#pickle.dump(model, open('model/model.pkl', 'wb'))\n",
    "#pickle.dump(scaler, open('model/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tree\n",
    "\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "tmp_dir = os.path.join(os.getcwd(), 'tmp')\n",
    "if not os.path.isdir(tmp_dir):\n",
    "    os.mkdir(tmp_dir)\n",
    "graph_file = os.path.join(tmp_dir, 'tree.dot')\n",
    "png_file = os.path.join(tmp_dir, 'tree.png')\n",
    "\n",
    "export_graphviz(estimator, out_file=graph_file, feature_names=feature_names,\n",
    "                class_names=None, rounded=True, proportion=False, precision=2, filled=True)\n",
    "\n",
    "call(['dot', '-Tpng', graph_file, '-o', png_file, '-Gdpi=600'])\n",
    "\n",
    "Image(filename=png_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bf1a5cf4aff157dbe1350d0c2c26794d3fa2cf7cb44058364317892fb1e2f69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
